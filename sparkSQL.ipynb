{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237a14de-be3b-4fed-b0f5-4d37565b7bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/anaconda3/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: py4j<0.10.9.10,>=0.10.9.7 in /opt/anaconda3/lib/python3.12/site-packages (from pyspark) (0.10.9.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f26c8a-7569-4f45-9dcf-94599782f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41db2797-2568-466b-8f3e-9eac38528fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/27 11:36:56 WARN Utils: Your hostname, Noas-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 192.168.0.106 instead (on interface en0)\n",
      "25/12/27 11:36:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/27 11:36:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark-jupyter-demo\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9987a9-c631-4e52-8e89-cd63e6409d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----+\n",
      "|   Car|Model|Year|\n",
      "+------+-----+----+\n",
      "|   Kia| Niro|2025|\n",
      "|Toyota| Rav4|2019|\n",
      "|   BYD|Atto3|2024|\n",
      "+------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the setup\n",
    "data = [(\"Kia\", \"Niro\", 2025), (\"Toyota\", \"Rav4\", 2019), (\"BYD\", \"Atto3\", 2024)]\n",
    "df = spark.createDataFrame(data, [\"Car\", \"Model\", \"Year\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b0e7a7-0b2d-4d09-851e-a17cd204af2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- episode_id: string (nullable = true)\n",
      " |-- number: string (nullable = true)\n",
      " |-- raw_text: string (nullable = true)\n",
      " |-- timestamp_in_ms: string (nullable = true)\n",
      " |-- speaking_line: string (nullable = true)\n",
      " |-- character_id: string (nullable = true)\n",
      " |-- location_id: string (nullable = true)\n",
      " |-- raw_character_text: string (nullable = true)\n",
      " |-- raw_location_text: string (nullable = true)\n",
      " |-- spoken_words: string (nullable = true)\n",
      " |-- normalized_text: string (nullable = true)\n",
      " |-- word_count: string (nullable = true)\n",
      "\n",
      "+----+----------+------+--------------------+---------------+-------------+------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  id|episode_id|number|            raw_text|timestamp_in_ms|speaking_line|character_id|location_id|  raw_character_text|   raw_location_text|        spoken_words|     normalized_text|word_count|\n",
      "+----+----------+------+--------------------+---------------+-------------+------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|9549|        32|   209|Miss Hoover: No, ...|         848000|         true|         464|          3|         Miss Hoover|Springfield Eleme...|No, actually, it ...|no actually it wa...|        31|\n",
      "|9550|        32|   210|Lisa Simpson: (NE...|         856000|         true|           9|          3|        Lisa Simpson|Springfield Eleme...|Where's Mr. Bergs...| wheres mr bergstrom|         3|\n",
      "|9551|        32|   211|Miss Hoover: I do...|         856000|         true|         464|          3|         Miss Hoover|Springfield Eleme...|I don't know. Alt...|i dont know altho...|        22|\n",
      "|9552|        32|   212|Lisa Simpson: Tha...|         864000|         true|           9|          3|        Lisa Simpson|Springfield Eleme...|That life is wort...|that life is wort...|         5|\n",
      "|9553|        32|   213|Edna Krabappel-Fl...|         864000|         true|          40|          3|Edna Krabappel-Fl...|Springfield Eleme...|The polls will be...|the polls will be...|        33|\n",
      "+----+----------+------+--------------------+---------------+-------------+------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "+---+---------------------------------+\n",
      "|wc |raw_text                         |\n",
      "+---+---------------------------------+\n",
      "|1  |Homer Simpson: Oh.               |\n",
      "|1  |Homer Simpson: And?              |\n",
      "|1  |Bart Simpson: Lewis?             |\n",
      "|1  |Homer Simpson: (SHOCKED) Me?     |\n",
      "|1  |Wendell Borton: Yayyyyyyyyyyyyyy!|\n",
      "|1  |Lisa Simpson: Baboon!            |\n",
      "|1  |Lisa Simpson: Yeah.              |\n",
      "|1  |Lisa Simpson: No!                |\n",
      "|1  |Homer Simpson: Oh.               |\n",
      "|1  |Homer Simpson: Nuts.             |\n",
      "+---+---------------------------------+\n",
      "only showing top 10 rows\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   86678|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lines = spark.read.format(\"com.databricks.spark.csv\").options(header='true') \\\n",
    " .option(\"delimiter\", \",\").option(\"quote\", '\"') \\\n",
    " .option(\"escape\", '\"').option(\"multiLine\", True) \\\n",
    " .load(\"/Users/noalevy/big_data/ex3/pyspark/simpsons/simpsons_script_lines.csv\")\n",
    "df_lines.createOrReplaceTempView(\"lines_table\")\n",
    "## print lines file schema\n",
    "df_lines.printSchema()\n",
    "## print all fields for first 5 rows\n",
    "spark.sql(\"SELECT * from lines_table\").show(5)\n",
    "## print the shortest 10 script lines:\n",
    "spark.sql(\"SELECT int(word_count) AS wc, raw_text FROM lines_table WHERE TRY_CAST(word_count AS INT) > 0 ORDER BY wc \").show(10,False)\n",
    "## count the scenes that took more than 10 minutes\n",
    "spark.sql(\"SELECT count(*) FROM lines_table WHERE TRY_CAST(timestamp_in_ms AS INT) > (10 * 60 * 1000)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc82be-71d9-48dc-a256-6734c4f7b15e",
   "metadata": {},
   "source": [
    "## Ex1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d8951-2d45-4aa9-9b49-b09402fb3389",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02fd60cc-52de-43da-8fea-247817e298bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               name\n",
      "0                     Springfield Elementary School\n",
      "1                                  Springfield Mall\n",
      "2                   Springfield Nuclear Power Plant\n",
      "3                       Springfield Downs Dog Track\n",
      "4                                 SPRINGFIELD DOWNS\n",
      "5                                  SPRINGFIELD DOWN\n",
      "6                     SPRINGFIELD DOWNS PARKING LOT\n",
      "7          Springfield Elementary School Playground\n",
      "8                             Springfield Town Hall\n",
      "9             Springfield Elementary School Hallway\n",
      "10          Springfield Elementary School Cafeteria\n",
      "11                    Springfield Retirement Castle\n",
      "12   Grampa's Room at Springfield Retirement Castle\n",
      "13                              Springfield Library\n",
      "14               Springfield Elementary School Yard\n",
      "15                      First Church of Springfield\n",
      "16            Springfield Elementary School Library\n",
      "17                              Springfield Airport\n",
      "18                       Springfield Police Station\n",
      "19                     Springfield Courthouse Steps\n",
      "20           Springfield High School Football Field\n",
      "21                               Springfield County\n",
      "22                                      Springfield\n",
      "23                                 Lake Springfield\n",
      "24                         TOP OF MOUNT SPRINGFIELD\n",
      "25                        Springfield Plasma Center\n",
      "26                             Springfield Speedway\n",
      "27                     Springfield General Hospital\n",
      "28                               Springfield Street\n",
      "29                                Springfield Gorge\n",
      "30                     SPRINGFIELD HOSPITAL HALLWAY\n",
      "31            Springfield Elementary School Grounds\n",
      "32                               Springfield Museum\n",
      "33            DREAMLIKE SUBURBAN SPRINGFIELD STREET\n",
      "34                          Springfield High School\n",
      "35                      Springfield High School Gym\n",
      "36                 SPRINGFIELD REVOLVING RESTAURANT\n",
      "37                        SPRINGFIELD JEWELRY STORE\n",
      "38                    SPRINGFIELD STARDUST BALLROOM\n",
      "39       SPRINGFIELD COMMUNITY COLLEGE REGISTRATION\n",
      "40                           SPRINGFIELD ART MUSEUM\n",
      "41                    Springfield Convention Center\n",
      "42                                 Springfield Bank\n",
      "43                                 SPRINGFIELD JAIL\n",
      "44                      Springfield National Forest\n",
      "45           Springfield Elementary School Bus Stop\n",
      "46                             Downtown Springfield\n",
      "47                               Springfield Prison\n",
      "48                          SPRINGFIELD COUNTY JAIL\n",
      "49  RANDOM SHOTS OF SPRINGFIELD NUCLEAR POWER PLANT\n"
     ]
    }
   ],
   "source": [
    "## print the first 50 locations that has the word \"Springfield\" in them , ignoring letters case.\n",
    "\n",
    "df_locations = spark.read.format(\"com.databricks.spark.csv\").options(header='true') \\\n",
    " .option(\"delimiter\", \",\").option(\"quote\", '\"') \\\n",
    " .option(\"escape\", '\"').option(\"multiLine\", True) \\\n",
    " .load(\"/Users/noalevy/big_data/ex3/pyspark/simpsons/simpsons_locations.csv\")\n",
    "\n",
    "df_locations.createOrReplaceTempView(\"locations_table\")\n",
    "\n",
    "df_result_first = spark.sql(\"SELECT name FROM locations_table WHERE normalized_name like '%springfield%'\")\n",
    "\n",
    "df_result_first = df_result_first.toPandas()\n",
    "\n",
    "print(df_result_first.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e3f7d-e899-46b8-b454-e00cbc0b0b8b",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e626f249-8b6c-450f-b993-55bbcf4df2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             raw_text\n",
      "0   (JERUSALEM ROYAL PALACE: ext. jerusalem royal ...\n",
      "1         Bart Simpson: I'm bored. Send in my jester.\n",
      "2   Krusty the Clown: Hey, hey, King David! (GOES ...\n",
      "3                    Bart Simpson: What else you got?\n",
      "4   Krusty the Clown: Ahh... yeah... well, wait a ...\n",
      "5                  Methuselah Grampa: (PAINED SOUNDS)\n",
      "6   Bart Simpson: Methuselah, my oldest friend. Wh...\n",
      "7   Methuselah Grampa: (WEAK, PAINED GROAN) It was...\n",
      "8   Bart Simpson: (PUZZLED) But Goliath is dead. I...\n",
      "9   Methuselah Grampa: No, it was his son, Goliath...\n",
      "10  Bart Simpson: (MELODRAMATIC) Nooo... (THEN, ST...\n",
      "11      (Jerusalem: EXT. JERUSALEM - FIELD OF BATTLE)\n",
      "12  Bart Simpson: (COCKY) I'll just give Goliath T...\n",
      "13  Santa's Little Helper: (DOPEY \"DAVEY AND GOLIA...\n",
      "14                Bart Simpson: (ANNOYED) Quiet, you.\n",
      "15  Santa's Little Helper: Oh, you've gotten prett...\n",
      "16       Goliath/nelson: (OMINOUS) Let's get it on...\n",
      "17        Santa's Little Helper: See ya later, Davey.\n",
      "18           Bart Simpson: You killed my best friend.\n",
      "19                            Crowd: (EXCITED \"WOOO\")\n"
     ]
    }
   ],
   "source": [
    "## print 20 quotes that are located in any place that has Jerusalem in its name.\n",
    "## Note that Jerusalem may appear in any case and in any part of the location name.\n",
    "## Use JOIN for this query on another table\n",
    "\n",
    "df_simpsons_script_lines = spark.read.format(\"com.databricks.spark.csv\").options(header='true') \\\n",
    " .option(\"delimiter\", \",\").option(\"quote\", '\"') \\\n",
    " .option(\"escape\", '\"').option(\"multiLine\", True) \\\n",
    " .load(\"/Users/noalevy/big_data/ex3/pyspark/simpsons/simpsons_script_lines.csv\")\n",
    "\n",
    "df_simpsons_script_lines.createOrReplaceTempView(\"quotes_table\")\n",
    "\n",
    "df_result_two = spark.sql(\"SELECT raw_text FROM quotes_table JOIN locations_table ON quotes_table.location_id = locations_table.id \\\n",
    "            WHERE normalized_name like '%jerusalem%'\")\n",
    "\n",
    "df_result_two = df_result_two.toPandas()\n",
    "\n",
    "print(df_result_two.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae5b60-754b-49da-b024-6488c4ab159b",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6ad90ba-3260-4c58-8e8c-79d50c41a9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           location  line_count\n",
      "0                      simpson home       35059\n",
      "1     springfield elementary school        7092\n",
      "2                        moe tavern        4628\n",
      "3   springfield nuclear power plant        3594\n",
      "4                       kwik-e-mart        1476\n",
      "5       first church of springfield        1416\n",
      "6               simpson living room        1378\n",
      "7                springfield street        1334\n",
      "8                       springfield        1314\n",
      "9                       simpson car        1239\n",
      "10                    flanders home        1166\n",
      "11                           street        1124\n",
      "12            springfield town hall        1103\n",
      "13    springfield retirement castle        1049\n",
      "14                      burns manor         998\n",
      "15                 springfield mall         833\n",
      "16                  simpson kitchen         816\n",
      "17                        courtroom         813\n",
      "18                   bart treehouse         767\n",
      "19                     bart bedroom         766\n"
     ]
    }
   ],
   "source": [
    "## print first 20 most used locations with the count of lines spoken in them.\n",
    "## use GROUP BY for that\n",
    "\n",
    "df_result_third = spark.sql(\"SELECT locations_table.normalized_name AS location, \\\n",
    "            COUNT(*) AS line_count FROM quotes_table \\\n",
    "            JOIN locations_table ON quotes_table.location_id = locations_table.id \\\n",
    "            GROUP BY locations_table.normalized_name \\\n",
    "            ORDER BY line_count DESC \\\n",
    "            LIMIT 20 \\\n",
    "            \")\n",
    "\n",
    "df_result_third = df_result_third.toPandas()\n",
    "\n",
    "print(df_result_third.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9d518-97a7-425e-91f9-d41539f8ba8a",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f1ed103-0d47-449b-ba72-f029a70af45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season  number_of_episodes  imdb_avg_rating\n",
      "0       5                  22         8.336364\n",
      "1       7                  25         8.324000\n",
      "2       6                  25         8.312000\n",
      "3       4                  22         8.268182\n",
      "4       8                  25         8.220000\n",
      "5       3                  24         8.154167\n",
      "6       2                  22         8.040909\n",
      "7       9                  25         7.844000\n",
      "8       1                  13         7.807692\n",
      "9      10                  23         7.569565\n",
      "10     12                  21         7.361905\n",
      "11     11                  22         7.290909\n",
      "12     13                  22         7.140909\n",
      "13     14                  22         7.077273\n",
      "14     15                  22         7.045455\n",
      "15     16                  21         7.042857\n",
      "16     18                  22         7.000000\n",
      "17     19                  20         6.935000\n",
      "18     20                  21         6.895238\n",
      "19     17                  22         6.863636\n",
      "20     25                  22         6.831818\n",
      "21     21                  23         6.821739\n",
      "22     23                  22         6.813636\n",
      "23     22                  22         6.804545\n",
      "24     27                  22         6.786364\n",
      "25     24                  22         6.777273\n",
      "26     26                  22         6.704545\n",
      "27     28                   4         6.600000\n"
     ]
    }
   ],
   "source": [
    "## find the seasons in which the average imdb rating was the highest.\n",
    "## Print the seasons number, the number of episodes in each one and the average rating\n",
    "## in a descending order from highest average rating to lowest.\n",
    "\n",
    "df_simpsons_episodes = spark.read.format(\"com.databricks.spark.csv\").options(header='true') \\\n",
    " .option(\"delimiter\", \",\").option(\"quote\", '\"') \\\n",
    " .option(\"escape\", '\"').option(\"multiLine\", True) \\\n",
    " .load(\"/Users/noalevy/big_data/ex3/pyspark/simpsons/simpsons_episodes.csv\")\n",
    "\n",
    "df_simpsons_episodes.createOrReplaceTempView(\"episodes_table\")\n",
    "\n",
    "df_result_fourth = spark.sql(\"SELECT season, COUNT(*) AS number_of_episodes, AVG(imdb_rating) AS imdb_avg_rating \\\n",
    "            FROM episodes_table \\\n",
    "            GROUP BY season \\\n",
    "            ORDER BY AVG(imdb_rating) DESC \")\n",
    "\n",
    "df_result_fourth = df_result_fourth.toPandas()\n",
    "\n",
    "print(df_result_fourth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a71c14-ec5a-45e5-92e0-9e2a2a4175e0",
   "metadata": {},
   "source": [
    "## EX 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89299761-93e3-4fce-b950-4bc6620f9fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  character_name  title_appearances\n",
      "0          Homer                 55\n",
      "1           Bart                 42\n",
      "2           Lisa                 38\n",
      "3          Marge                 20\n",
      "4         Maggie                  2\n"
     ]
    }
   ],
   "source": [
    "## The query is - which of the characters appears the most in the episodes titles?\n",
    "## The characters that are being checked are - Homer, Lisa, Bart, Maggie, Marge\n",
    "\n",
    "df_ex2 = spark.sql(\"SELECT 'Homer' AS character_name, COUNT(*) AS title_appearances \\\n",
    "                    FROM episodes_table \\\n",
    "                    WHERE title LIKE '%Homer%' \\\n",
    "                    UNION ALL \\\n",
    "                    SELECT 'Bart' AS character_name, COUNT(*) AS title_appearances \\\n",
    "                    FROM episodes_table \\\n",
    "                    WHERE title LIKE '%Bart%' \\\n",
    "                    UNION ALL \\\n",
    "                    SELECT 'Maggie' AS character_name, COUNT(*) AS title_appearances \\\n",
    "                    FROM episodes_table \\\n",
    "                    WHERE title LIKE '%Maggie%' \\\n",
    "                    UNION ALL \\\n",
    "                    SELECT 'Lisa' AS character_name, COUNT(*) AS title_appearances \\\n",
    "                    FROM episodes_table \\\n",
    "                    WHERE title LIKE '%Lisa%' \\\n",
    "                    UNION ALL \\\n",
    "                    SELECT 'Marge' AS character_name, COUNT(*) AS title_appearances \\\n",
    "                    FROM episodes_table \\\n",
    "                    WHERE title LIKE '%Marge%' \\\n",
    "                    ORDER BY title_appearances DESC \\\n",
    "                    \")\n",
    "\n",
    "df_ex2 = df_ex2.toPandas()\n",
    "\n",
    "print(df_ex2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (OSM)",
   "language": "python",
   "name": "py39_osm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
